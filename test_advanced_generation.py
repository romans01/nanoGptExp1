#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º
"""

import os
import torch
import subprocess
from pathlib import Path

def test_model_generation(model_path, model_name, prompts, max_new_tokens=200):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–ª—è –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    
    print(f"\nüé≠ {model_name.upper()}:")
    print("-" * 50)
    
    if not os.path.exists(model_path):
        print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
        return None
    
    results = {}
    
    for prompt in prompts:
        print(f"\nüéØ –ü—Ä–æ–º–ø—Ç: '{prompt}'")
        print("=" * 30)
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º sample_centered.py –¥–ª—è —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            if 'baseline' in model_name.lower():
                sample_script = 'sample.py'
            else:
                sample_script = 'sample_centered.py'
            
            cmd = [
                'python', sample_script,
                '--out_dir', model_path,
                '--start', prompt,
                '--num_samples', '1',
                '--max_new_tokens', str(max_new_tokens),
                '--temperature', '0.8',
                '--top_k', '200'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                output_lines = result.stdout.strip().split('\n')
                
                # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ "No meta.pkl found" –∏–ª–∏ –ø–æ—Ö–æ–∂–∏—Ö
                generation_started = False
                generated_text = []
                
                for line in output_lines:
                    if prompt in line and not generation_started:
                        generation_started = True
                        generated_text.append(line)
                    elif generation_started:
                        generated_text.append(line)
                
                if generated_text:
                    full_text = '\n'.join(generated_text)
                    print(full_text)
                    results[prompt] = full_text
                else:
                    print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç")
                    results[prompt] = "–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è"
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {result.stderr[:200]}")
                results[prompt] = f"–û—à–∏–±–∫–∞: {result.stderr[:100]}"
                
        except subprocess.TimeoutExpired:
            print("‚è±Ô∏è  –¢–∞–π–º–∞—É—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
            results[prompt] = "–¢–∞–π–º–∞—É—Ç"
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
            results[prompt] = f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {str(e)}"
    
    return results

def compare_generations():
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π"""
    
    print("üé≠ –°–†–ê–í–ù–ï–ù–ò–ï –ì–ï–ù–ï–†–ê–¶–ò–ò –õ–£–ß–®–ò–• –ú–û–î–ï–õ–ï–ô")
    print("=" * 60)
    
    # –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–ª—É—á—à–∏–µ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º 1K —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)
    models = [
        {
            'path': 'out-advanced-1k-baseline_1k',
            'name': 'Baseline 1K',
            'description': '–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è –≥—Ä—É–ø–ø–∞'
        },
        {
            'path': 'out-advanced-1k-embeddings_centered_1k', 
            'name': 'Embeddings Centered 1K',
            'description': 'ü•á –ü–û–ë–ï–î–ò–¢–ï–õ–¨ (+2.26%)'
        },
        {
            'path': 'out-advanced-1k-qk_plus_value_1k',
            'name': 'QK + Value 1K', 
            'description': 'ü•à 2-–µ –º–µ—Å—Ç–æ (+1.89%)'
        },
        {
            'path': 'out-advanced-1k-value_centered_1k',
            'name': 'Value Centered 1K',
            'description': 'Value —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ (+1.13%)'
        }
    ]
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã
    prompts = [
        "ROMEO:",
        "JULIET:", 
        "To be or not to be",
        "Once upon a time",
        "The meaning of life"
    ]
    
    all_results = {}
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
    for model in models:
        print(f"\n{'='*60}")
        print(f"üöÄ –¢–µ—Å—Ç–∏—Ä—É–µ–º: {model['name']}")
        print(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ: {model['description']}")
        print(f"üìÅ –ü—É—Ç—å: {model['path']}")
        
        results = test_model_generation(
            model['path'], 
            model['name'], 
            prompts,
            max_new_tokens=150
        )
        
        if results:
            all_results[model['name']] = results
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    create_comparison_report(all_results, prompts)
    
    return all_results

def create_comparison_report(all_results, prompts):
    """–°–æ–∑–¥–∞–µ—Ç —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–π"""
    
    print(f"\n\nüìä –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ì–ï–ù–ï–†–ê–¶–ò–ô")
    print("=" * 60)
    
    for prompt in prompts:
        print(f"\nüéØ –ü–†–û–ú–ü–¢: '{prompt}'")
        print("=" * 40)
        
        for model_name, results in all_results.items():
            if prompt in results:
                print(f"\nüé≠ {model_name}:")
                print("-" * 25)
                
                generation = results[prompt]
                if len(generation) > 300:
                    generation = generation[:300] + "..."
                
                print(generation)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª
    save_generation_report(all_results, prompts)

def save_generation_report(all_results, prompts):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª"""
    
    timestamp = __import__('datetime').datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = f"training_plots/generation_comparison_{timestamp}.txt"
    
    os.makedirs('training_plots', exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("üé≠ –°–†–ê–í–ù–ï–ù–ò–ï –ì–ï–ù–ï–†–ê–¶–ò–ò –õ–£–ß–®–ò–• –ú–û–î–ï–õ–ï–ô\n")
        f.write("=" * 60 + "\n\n")
        
        f.write("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í:\n")
        f.write("ü•á Embeddings Centered: +2.26% —É–ª—É—á—à–µ–Ω–∏–µ\n")
        f.write("ü•à QK + Value: +1.89% —É–ª—É—á—à–µ–Ω–∏–µ\n") 
        f.write("ü•â Value Centered: +1.13% —É–ª—É—á—à–µ–Ω–∏–µ\n")
        f.write("üìä Baseline: –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è –≥—Ä—É–ø–ø–∞\n\n")
        
        for prompt in prompts:
            f.write(f"\nüéØ –ü–†–û–ú–ü–¢: '{prompt}'\n")
            f.write("=" * 50 + "\n")
            
            for model_name, results in all_results.items():
                if prompt in results:
                    f.write(f"\nüé≠ {model_name}:\n")
                    f.write("-" * 30 + "\n")
                    f.write(f"{results[prompt]}\n")
        
        f.write(f"\n\nüìù –û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {timestamp}\n")
        f.write("üéØ –í—Å–µ –º–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã –Ω–∞ 1000 –∏—Ç–µ—Ä–∞—Ü–∏–π\n")
        f.write("üìä –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: 0.8\n")
        f.write("üî¢ –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤: 150\n")
    
    print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

def analyze_generation_quality(all_results):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π"""
    
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –ì–ï–ù–ï–†–ê–¶–ò–ô")
    print("=" * 40)
    
    quality_metrics = {}
    
    for model_name, results in all_results.items():
        metrics = {
            'avg_length': 0,
            'shakespeare_style': 0,
            'coherence': 0,
            'errors': 0
        }
        
        valid_generations = 0
        
        for prompt, generation in results.items():
            if "–û—à–∏–±–∫–∞" not in generation and "–¢–∞–π–º–∞—É—Ç" not in generation:
                valid_generations += 1
                
                # –î–ª–∏–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                metrics['avg_length'] += len(generation)
                
                # –°—Ç–∏–ª—å –®–µ–∫—Å–ø–∏—Ä–∞ (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
                shakespeare_words = ['thou', 'thee', 'thy', 'hath', 'doth', 'art', 'shall', 'whence', 'wherefore']
                shakespeare_score = sum(1 for word in shakespeare_words if word.lower() in generation.lower())
                metrics['shakespeare_style'] += shakespeare_score
                
                # –°–≤—è–∑–Ω–æ—Å—Ç—å (–æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–≤—Ç–æ—Ä–æ–≤)
                words = generation.split()
                if len(words) > 10:
                    unique_ratio = len(set(words)) / len(words)
                    metrics['coherence'] += unique_ratio
            else:
                metrics['errors'] += 1
        
        if valid_generations > 0:
            metrics['avg_length'] /= valid_generations
            metrics['shakespeare_style'] /= valid_generations
            metrics['coherence'] /= valid_generations
        
        quality_metrics[model_name] = metrics
        
        print(f"\nüìä {model_name}:")
        print(f"  üìè –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {metrics['avg_length']:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  üé≠ –°—Ç–∏–ª—å –®–µ–∫—Å–ø–∏—Ä–∞: {metrics['shakespeare_style']:.1f} —Å–ª–æ–≤")
        print(f"  üîó –°–≤—è–∑–Ω–æ—Å—Ç—å: {metrics['coherence']:.2f}")
        print(f"  ‚ùå –û—à–∏–±–∫–∏: {metrics['errors']}")
    
    return quality_metrics

def main():
    print("üé≠ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π")
    print("üéØ –¶–µ–ª—å: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")
    print("üìä –ú–æ–¥–µ–ª–∏: –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã 1K —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ sample_centered.py
    if not os.path.exists('sample_centered.py'):
        print("‚ö†Ô∏è  sample_centered.py –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º...")
        # –ú–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –∏–ª–∏ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏–∑ sample.py —Å –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏
        print("‚ÑπÔ∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π sample.py –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    all_results = compare_generations()
    
    if all_results:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        quality_metrics = analyze_generation_quality(all_results)
        
        print(f"\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìä –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(all_results)}")
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ training_plots/")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å")

if __name__ == "__main__":
    main()
