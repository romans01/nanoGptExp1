{
  "validation": {
    "steps": [
      0,
      25,
      50,
      75,
      100,
      125,
      150,
      175,
      200,
      225,
      250,
      275,
      300
    ],
    "train_loss": [
      4.2105,
      2.6162,
      2.5097,
      2.4814,
      2.4582,
      2.4129,
      2.3588,
      2.3091,
      2.2131,
      2.1199,
      2.0219,
      1.9367,
      1.8751
    ],
    "val_loss": [
      4.2035,
      2.6188,
      2.5223,
      2.4901,
      2.4825,
      2.4261,
      2.3976,
      2.3362,
      2.2681,
      2.1922,
      2.1127,
      2.0384,
      1.9918
    ]
  },
  "training": {
    "iters": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200,
      210,
      220,
      230,
      240,
      250,
      260,
      270,
      280,
      290,
      300
    ],
    "loss": [
      4.2205,
      2.9882,
      2.7215,
      2.5947,
      2.5885,
      2.4934,
      2.5186,
      2.5067,
      2.4979,
      2.4895,
      2.453,
      2.4417,
      2.4595,
      2.412,
      2.3912,
      2.3829,
      2.3779,
      2.3104,
      2.3123,
      2.3266,
      2.2719,
      2.2449,
      2.1897,
      2.1308,
      2.1187,
      2.1094,
      2.0514,
      2.032,
      2.02,
      1.9884,
      1.9606
    ],
    "time": [
      1942.97,
      27.82,
      30.29,
      27.9,
      31.13,
      649.32,
      30.32,
      27.87,
      27.83,
      27.83,
      653.52,
      27.91,
      27.9,
      27.87,
      29.57,
      657.98,
      27.87,
      27.93,
      31.33,
      29.87,
      690.12,
      27.88,
      28.91,
      28.56,
      27.94,
      689.05,
      30.94,
      27.9,
      27.85,
      27.91,
      670.49
    ],
    "mfu": [
      0,
      26.76,
      26.54,
      26.56,
      26.29,
      23.78,
      23.86,
      24.14,
      24.4,
      24.64,
      22.29,
      22.73,
      23.12,
      23.48,
      23.65,
      21.4,
      21.93,
      22.4,
      22.54,
      22.78,
      20.61,
      21.22,
      21.67,
      22.11,
      22.56,
      20.42,
      20.78,
      21.37,
      21.91,
      22.38,
      20.26
    ]
  },
  "model_info": {
    "parameters": "21.27M",
    "vocab_size": 65,
    "n_layer": "12",
    "n_head": "12",
    "n_embd": "384",
    "block_size": "256",
    "batch_size": "64",
    "learning_rate": 0.001,
    "dropout": 0.2,
    "max_iters": "5000",
    "dataset": "shakespeare_char"
  }
}