{
  "validation": {
    "steps": [
      0,
      50,
      100,
      150,
      200,
      250,
      300,
      350,
      400,
      450,
      500,
      550,
      600,
      650,
      700,
      750,
      800,
      850,
      900,
      950,
      1000
    ],
    "train_loss": [
      10.9776,
      6.1935,
      4.89,
      4.5011,
      4.1479,
      3.9587,
      3.7068,
      3.4002,
      3.2558,
      2.9964,
      2.6672,
      2.3439,
      1.9903,
      1.7184,
      1.4558,
      1.2194,
      0.9997,
      0.8646,
      0.7295,
      0.6487,
      0.5821
    ],
    "val_loss": [
      10.9793,
      6.3391,
      5.3589,
      5.1446,
      4.9924,
      4.8563,
      4.9031,
      4.7342,
      4.851,
      4.6821,
      4.8199,
      4.8792,
      4.9311,
      5.1841,
      5.1768,
      5.3969,
      5.5464,
      5.6875,
      5.7563,
      5.8473,
      5.792
    ]
  },
  "training": {
    "iters": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200,
      210,
      220,
      230,
      240,
      250,
      260,
      270,
      280,
      290,
      300,
      310,
      320,
      330,
      340,
      350,
      360,
      370,
      380,
      390,
      400,
      410,
      420,
      430,
      440,
      450,
      460,
      470,
      480,
      490,
      500,
      510,
      520,
      530,
      540,
      550,
      560,
      570,
      580,
      590,
      600,
      610,
      620,
      630,
      640,
      650,
      660,
      670,
      680,
      690,
      700,
      710,
      720,
      730,
      740,
      750,
      760,
      770,
      780,
      790,
      800,
      810,
      820,
      830,
      840,
      850,
      860,
      870,
      880,
      890,
      900,
      910,
      920,
      930,
      940,
      950,
      960,
      970,
      980,
      990,
      1000
    ],
    "loss": [
      10.9868,
      8.9955,
      8.2706,
      7.6623,
      6.8408,
      6.3536,
      5.7936,
      5.5216,
      5.1281,
      5.1593,
      5.0697,
      4.7769,
      4.7557,
      4.5977,
      4.6463,
      4.4347,
      4.4801,
      4.4071,
      4.095,
      4.2257,
      4.2309,
      4.0996,
      4.4172,
      4.0617,
      3.9918,
      4.1044,
      4.0838,
      4.0733,
      3.7777,
      3.73,
      3.9252,
      3.9089,
      3.5101,
      3.6173,
      3.7526,
      3.8413,
      3.0933,
      3.4513,
      3.4934,
      3.368,
      3.3907,
      3.1627,
      3.3127,
      3.3196,
      3.125,
      3.1267,
      2.8077,
      2.9133,
      3.039,
      2.8613,
      2.7835,
      2.8536,
      2.8176,
      2.7502,
      2.7155,
      2.4896,
      2.2982,
      2.3075,
      2.2699,
      2.5619,
      2.064,
      2.1619,
      2.0361,
      2.3331,
      1.7199,
      1.84,
      1.6907,
      1.7981,
      1.7139,
      1.8465,
      1.6696,
      1.6946,
      1.4384,
      1.535,
      1.5304,
      1.4862,
      1.3847,
      1.532,
      1.3151,
      1.4965,
      1.1516,
      1.0923,
      1.0276,
      1.1227,
      1.3282,
      1.0063,
      1.1136,
      1.0048,
      0.9559,
      1.1952,
      1.0206,
      0.9224,
      1.0925,
      1.015,
      0.8069,
      0.8367,
      0.953,
      0.9356,
      0.8648,
      1.0546,
      0.7353
    ],
    "time": [
      3322.32,
      230.32,
      231.99,
      242.52,
      223.77,
      3317.99,
      223.63,
      223.76,
      271.11,
      223.96,
      3208.3,
      238.51,
      223.69,
      274.14,
      260.15,
      2789.19,
      256.52,
      241.08,
      229.37,
      233.96,
      3442.8,
      231.68,
      228.75,
      224.38,
      227.82,
      3542.12,
      257.1,
      259.24,
      253.37,
      258.37,
      3519.66,
      233.02,
      230.68,
      260.02,
      230.83,
      3410.67,
      224.52,
      231.51,
      227.74,
      249.09,
      3344.2,
      262.38,
      268.56,
      246.44,
      246.74,
      3562.38,
      253.47,
      275.92,
      253.05,
      255.83,
      3383.39,
      254.54,
      255.95,
      254.55,
      250.53,
      3232.16,
      253.24,
      253.37,
      253.64,
      247.26,
      3488.47,
      255.3,
      254.19,
      255.41,
      252.2,
      3553.7,
      254.65,
      250.89,
      253.12,
      252.5,
      3319.1,
      250.83,
      250.62,
      254.24,
      254.73,
      3255.95,
      253.02,
      256.23,
      254.49,
      254.52,
      3572.64,
      250.41,
      252.33,
      251.41,
      255.81,
      3091.6,
      248.45,
      252.22,
      252.65,
      250.83,
      3554.04,
      253.81,
      253.66,
      252.17,
      251.63,
      3557.6,
      250.48,
      253.1,
      253.71,
      254.22,
      3537.42
    ],
    "mfu": [
      0,
      31.11,
      31.09,
      30.93,
      31.04,
      28.15,
      28.54,
      28.89,
      28.64,
      28.98,
      26.3,
      26.68,
      27.21,
      27.11,
      27.15,
      24.69,
      25.02,
      25.49,
      26.06,
      26.52,
      24.07,
      24.76,
      25.42,
      26.07,
      26.61,
      24.15,
      24.52,
      24.83,
      25.18,
      25.43,
      23.09,
      23.86,
      24.58,
      24.88,
      25.49,
      23.15,
      24.03,
      24.72,
      25.4,
      25.73,
      23.37,
      23.77,
      24.06,
      24.56,
      25.01,
      22.71,
      23.26,
      23.54,
      24.01,
      24.41,
      22.18,
      22.78,
      23.3,
      23.79,
      24.27,
      22.06,
      22.69,
      23.25,
      23.75,
      24.27,
      22.05,
      22.65,
      23.2,
      23.69,
      24.16,
      21.95,
      22.57,
      23.16,
      23.68,
      24.15,
      21.95,
      22.61,
      23.21,
      23.71,
      24.15,
      21.95,
      22.59,
      23.13,
      23.63,
      24.08,
      21.88,
      22.55,
      23.13,
      23.67,
      24.1,
      21.93,
      22.62,
      23.2,
      23.71,
      24.2,
      21.98,
      22.61,
      23.17,
      23.69,
      24.17,
      21.96,
      22.62,
      23.19,
      23.7,
      24.14,
      21.93
    ]
  },
  "model_info": {
    "parameters": "208.54M",
    "n_layer": "24",
    "n_head": "12",
    "n_embd": "768",
    "block_size": "512",
    "batch_size": "8",
    "learning_rate": 0.0003,
    "dropout": 0.1,
    "max_iters": "1000",
    "dataset": "shakespeare"
  }
}