{
  "validation": {
    "steps": [
      0,
      50,
      100,
      150,
      200,
      250,
      300,
      350,
      400,
      450,
      500,
      550,
      600,
      650,
      700,
      750,
      800,
      850,
      900,
      950,
      1000
    ],
    "train_loss": [
      10.9778,
      6.1908,
      4.8981,
      4.5016,
      4.1841,
      4.0346,
      3.8302,
      3.5918,
      3.5263,
      3.3512,
      3.1592,
      2.9961,
      2.8195,
      2.7223,
      2.5809,
      2.4533,
      2.2849,
      2.1049,
      1.9901,
      1.8928,
      1.8113
    ],
    "val_loss": [
      10.9789,
      6.3359,
      5.3862,
      5.1279,
      5.0189,
      4.9243,
      4.9919,
      4.8753,
      4.942,
      4.7685,
      4.8601,
      4.8874,
      4.8364,
      5.0034,
      4.9294,
      5.0366,
      5.101,
      5.2321,
      5.2579,
      5.3288,
      5.2421
    ]
  },
  "training": {
    "iters": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200,
      210,
      220,
      230,
      240,
      250,
      260,
      270,
      280,
      290,
      300,
      310,
      320,
      330,
      340,
      350,
      360,
      370,
      380,
      390,
      400,
      410,
      420,
      430,
      440,
      450,
      460,
      470,
      480,
      490,
      500,
      510,
      520,
      530,
      540,
      550,
      560,
      570,
      580,
      590,
      600,
      610,
      620,
      630,
      640,
      650,
      660,
      670,
      680,
      690,
      700,
      710,
      720,
      730,
      740,
      750,
      760,
      770,
      780,
      790,
      800,
      810,
      820,
      830,
      840,
      850,
      860,
      870,
      880,
      890,
      900,
      910,
      920,
      930,
      940,
      950,
      960,
      970,
      980,
      990,
      1000
    ],
    "loss": [
      10.9877,
      8.9969,
      8.2697,
      7.6615,
      6.8417,
      6.3506,
      5.7934,
      5.5338,
      5.1399,
      5.1624,
      5.0851,
      4.7848,
      4.766,
      4.6036,
      4.642,
      4.4307,
      4.5156,
      4.4138,
      4.1441,
      4.2577,
      4.2717,
      4.139,
      4.4497,
      4.1254,
      4.0441,
      4.162,
      4.146,
      4.119,
      3.8938,
      3.8202,
      4.0219,
      4.0297,
      3.6706,
      3.7725,
      3.8893,
      4.0136,
      3.3137,
      3.6518,
      3.7469,
      3.6219,
      3.6342,
      3.4409,
      3.6177,
      3.6305,
      3.4556,
      3.4686,
      3.1721,
      3.31,
      3.4596,
      3.2737,
      3.3176,
      3.3279,
      3.3414,
      3.2132,
      3.2194,
      3.1364,
      2.874,
      3.0344,
      2.9895,
      3.2067,
      2.8264,
      2.9543,
      2.808,
      3.1207,
      2.6078,
      2.7903,
      2.5984,
      2.7545,
      2.6989,
      2.814,
      2.6104,
      2.6509,
      2.4557,
      2.6048,
      2.6421,
      2.5849,
      2.4763,
      2.6865,
      2.4889,
      2.5985,
      2.3448,
      2.1846,
      2.1319,
      2.1975,
      2.5737,
      2.206,
      2.2668,
      2.236,
      2.1429,
      2.4416,
      2.2627,
      2.0827,
      2.3428,
      2.2363,
      1.9241,
      2.1225,
      2.1407,
      2.1656,
      1.9804,
      2.3019,
      1.8808
    ],
    "time": [
      4266.86,
      271.47,
      272.88,
      273.5,
      269.84,
      3564.85,
      275.62,
      271.26,
      274.38,
      275.37,
      3281.72,
      271.32,
      271.73,
      267.93,
      271.35,
      3602.09,
      273.41,
      272.31,
      270.61,
      273.38,
      3615.91,
      273.4,
      272.42,
      271.93,
      271.93,
      2846.01,
      273.53,
      271.74,
      269.57,
      271.33,
      3563.64,
      273.77,
      272.2,
      271.36,
      271.35,
      3571.39,
      272.91,
      272.21,
      270.47,
      272.97,
      3615.47,
      273.0,
      272.88,
      269.46,
      271.3,
      3698.93,
      269.86,
      270.76,
      271.37,
      270.0,
      4145.47,
      273.71,
      272.76,
      272.63,
      275.01,
      3760.95,
      273.27,
      272.18,
      273.47,
      272.46,
      3817.11,
      271.35,
      270.42,
      272.04,
      267.65,
      3304.2,
      271.27,
      270.92,
      270.28,
      268.54,
      3570.43,
      268.92,
      270.58,
      270.57,
      270.82,
      3565.71,
      271.43,
      274.22,
      269.42,
      272.35,
      2889.72,
      272.49,
      273.16,
      271.81,
      272.96,
      3313.33,
      270.44,
      270.94,
      273.85,
      274.46,
      3291.09,
      272.01,
      263.13,
      257.21,
      275.23,
      3260.07,
      268.87,
      269.94,
      271.18,
      274.95,
      3268.45
    ],
    "mfu": [
      0,
      26.39,
      26.38,
      26.36,
      26.38,
      23.94,
      24.15,
      24.38,
      24.55,
      24.7,
      22.45,
      22.84,
      23.19,
      23.55,
      23.84,
      21.65,
      22.11,
      22.53,
      22.92,
      23.25,
      21.12,
      21.63,
      22.1,
      22.52,
      22.91,
      20.87,
      21.4,
      21.9,
      22.37,
      22.77,
      20.69,
      21.24,
      21.75,
      22.22,
      22.63,
      20.57,
      21.14,
      21.66,
      22.14,
      22.55,
      20.5,
      21.07,
      21.59,
      22.09,
      22.52,
      20.46,
      21.07,
      21.61,
      22.09,
      22.54,
      20.45,
      21.03,
      21.55,
      22.02,
      22.43,
      20.38,
      20.96,
      21.5,
      21.97,
      22.4,
      20.35,
      20.95,
      21.51,
      21.99,
      22.47,
      20.44,
      21.04,
      21.58,
      22.07,
      22.53,
      20.48,
      21.1,
      21.63,
      22.12,
      22.55,
      20.5,
      21.09,
      21.59,
      22.09,
      22.51,
      20.51,
      21.09,
      21.6,
      22.08,
      22.5,
      20.46,
      21.07,
      21.6,
      22.06,
      22.47,
      20.44,
      21.03,
      21.65,
      22.27,
      22.64,
      20.6,
      21.21,
      21.74,
      22.21,
      22.59,
      20.55
    ]
  },
  "model_info": {
    "parameters": "208.54M",
    "n_layer": "24",
    "n_head": "12",
    "n_embd": "768",
    "block_size": "512",
    "batch_size": "8",
    "learning_rate": 0.0003,
    "dropout": 0.1,
    "max_iters": "1000",
    "dataset": "shakespeare"
  }
}