{
  "validation": {
    "steps": [
      0,
      50,
      100,
      150,
      200,
      250,
      300,
      350,
      400,
      450,
      500,
      550,
      600,
      650,
      700,
      750,
      800,
      850,
      900,
      950,
      1000
    ],
    "train_loss": [
      10.9758,
      10.8088,
      8.2237,
      7.1776,
      7.0347,
      9.9707,
      10.5973,
      11.3656,
      10.0559,
      12.9063,
      9.7979,
      9.2054,
      9.6992,
      8.6463,
      9.2241,
      7.4127,
      7.8222,
      8.0677,
      8.224,
      8.7848,
      9.0901
    ],
    "val_loss": [
      10.9797,
      10.8276,
      8.4108,
      7.3111,
      7.2503,
      9.7123,
      10.8281,
      11.5016,
      10.1438,
      12.8889,
      9.873,
      9.2989,
      9.8091,
      8.7929,
      9.3113,
      7.5217,
      8.0601,
      8.2227,
      8.3728,
      8.9317,
      9.2373
    ]
  },
  "training": {
    "iters": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200,
      210,
      220,
      230,
      240,
      250,
      260,
      270,
      280,
      290,
      300,
      310,
      320,
      330,
      340,
      350,
      360,
      370,
      380,
      390,
      400,
      410,
      420,
      430,
      440,
      450,
      460,
      470,
      480,
      490,
      500,
      510,
      520,
      530,
      540,
      550,
      560,
      570,
      580,
      590,
      600,
      610,
      620,
      630,
      640,
      650,
      660,
      670,
      680,
      690,
      700,
      710,
      720,
      730,
      740,
      750,
      760,
      770,
      780,
      790,
      800,
      810,
      820,
      830,
      840,
      850,
      860,
      870,
      880,
      890,
      900,
      910,
      920,
      930,
      940,
      950,
      960,
      970,
      980,
      990,
      1000
    ],
    "loss": [
      10.9685,
      10.9775,
      10.4005,
      11.4905,
      9.7648,
      10.0497,
      11.0459,
      10.3492,
      10.9504,
      9.7163,
      8.0943,
      7.5486,
      7.5654,
      7.5128,
      7.1294,
      6.9179,
      7.1394,
      6.6836,
      6.5616,
      8.3822,
      6.9642,
      6.5352,
      6.6545,
      6.6911,
      6.6671,
      6.4556,
      6.5612,
      6.4882,
      6.6726,
      6.37,
      6.5316,
      8.2152,
      6.9149,
      7.6568,
      6.9104,
      6.4401,
      7.2146,
      6.4062,
      6.2836,
      10.7456,
      6.3965,
      6.2942,
      6.4526,
      6.5712,
      6.3457,
      6.3524,
      6.1564,
      6.3059,
      6.4073,
      6.2391,
      6.4414,
      7.2825,
      6.2994,
      6.4597,
      6.2819,
      6.3318,
      6.1252,
      6.514,
      6.3551,
      6.3669,
      6.3607,
      6.2735,
      9.5916,
      8.3037,
      6.1884,
      6.2209,
      6.1873,
      6.2585,
      6.3182,
      6.3756,
      6.2437,
      6.2245,
      6.2402,
      6.3597,
      7.037,
      6.7138,
      6.2643,
      6.5909,
      6.3925,
      8.5645,
      6.399,
      6.294,
      6.1548,
      9.1765,
      6.3263,
      6.2561,
      6.3341,
      6.2195,
      6.2372,
      6.3105,
      6.1521,
      6.2117,
      6.4267,
      6.4191,
      6.3271,
      6.226,
      6.3819,
      6.3638,
      6.2308,
      6.2558,
      6.1799
    ],
    "time": [
      3798.18,
      259.04,
      255.88,
      260.21,
      256.11,
      3200.99,
      256.61,
      257.59,
      253.83,
      258.25,
      3433.16,
      253.86,
      255.9,
      256.1,
      257.67,
      3253.42,
      257.4,
      255.77,
      254.14,
      259.01,
      3263.51,
      259.16,
      256.41,
      255.22,
      257.13,
      3518.17,
      258.77,
      256.37,
      256.45,
      254.09,
      3160.14,
      256.88,
      253.06,
      258.15,
      252.9,
      3214.27,
      252.49,
      259.79,
      254.76,
      255.69,
      3501.71,
      255.38,
      255.66,
      258.37,
      255.08,
      3549.14,
      259.64,
      257.31,
      258.28,
      256.17,
      3263.39,
      257.53,
      256.75,
      259.59,
      255.65,
      3017.07,
      256.46,
      257.28,
      253.79,
      257.45,
      3261.9,
      255.56,
      256.09,
      254.18,
      255.75,
      3133.57,
      255.75,
      258.17,
      254.95,
      257.28,
      3194.12,
      256.45,
      257.06,
      255.96,
      256.37,
      3179.57,
      259.82,
      252.64,
      257.3,
      255.74,
      3242.67,
      258.49,
      258.37,
      258.08,
      258.17,
      3249.06,
      258.05,
      255.24,
      257.55,
      256.98,
      3255.01,
      260.04,
      240.41,
      258.57,
      257.15,
      3181.56,
      252.42,
      258.67,
      255.62,
      255.16,
      3202.71
    ],
    "mfu": [
      0,
      27.66,
      27.7,
      27.68,
      27.71,
      25.16,
      25.44,
      25.68,
      25.93,
      26.11,
      23.71,
      24.16,
      24.55,
      24.89,
      25.18,
      22.88,
      23.38,
      23.84,
      24.28,
      24.62,
      22.37,
      22.9,
      23.41,
      23.87,
      24.27,
      22.05,
      22.61,
      23.15,
      23.63,
      24.08,
      21.9,
      22.5,
      23.08,
      23.55,
      24.03,
      21.85,
      22.5,
      23.01,
      23.52,
      23.97,
      21.78,
      22.41,
      22.97,
      23.44,
      23.91,
      21.72,
      22.31,
      22.86,
      23.35,
      23.81,
      21.65,
      22.27,
      22.83,
      23.31,
      23.78,
      21.64,
      22.27,
      22.83,
      23.37,
      23.81,
      21.65,
      22.29,
      22.86,
      23.39,
      23.86,
      21.7,
      22.33,
      22.87,
      23.4,
      23.84,
      21.68,
      22.31,
      22.86,
      23.38,
      23.83,
      21.68,
      22.27,
      22.88,
      23.37,
      23.84,
      21.67,
      22.28,
      22.82,
      23.32,
      23.76,
      21.61,
      22.22,
      22.81,
      23.31,
      23.77,
      21.61,
      22.2,
      22.96,
      23.44,
      23.88,
      21.72,
      22.39,
      22.92,
      23.43,
      23.89,
      21.73
    ]
  },
  "model_info": {
    "parameters": "208.54M",
    "n_layer": "24",
    "n_head": "12",
    "n_embd": "768",
    "block_size": "512",
    "batch_size": "8",
    "learning_rate": 0.0003,
    "dropout": 0.1,
    "max_iters": "1000",
    "dataset": "shakespeare"
  }
}