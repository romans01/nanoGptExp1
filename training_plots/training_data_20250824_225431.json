{
  "validation": {
    "steps": [
      0,
      50,
      100,
      150,
      200,
      250,
      300,
      350,
      400,
      450,
      500,
      550,
      600,
      650,
      700,
      750,
      800,
      850,
      900,
      950,
      1000
    ],
    "train_loss": [
      10.9111,
      6.0399,
      4.9127,
      4.5402,
      4.2202,
      4.0791,
      3.9497,
      3.8147,
      3.6973,
      3.567,
      3.5475,
      3.3736,
      3.2947,
      3.1761,
      3.0582,
      3.0654,
      2.9234,
      2.89,
      2.8278,
      2.8498,
      2.7234
    ],
    "val_loss": [
      10.8763,
      6.1441,
      5.2996,
      5.0468,
      4.9939,
      4.9595,
      4.8477,
      4.8643,
      4.8072,
      4.7434,
      4.7847,
      4.8347,
      4.8757,
      5.0048,
      4.9762,
      4.87,
      5.018,
      4.9816,
      4.8767,
      4.9878,
      4.9845
    ]
  },
  "training": {
    "iters": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200,
      210,
      220,
      230,
      240,
      250,
      260,
      270,
      280,
      290,
      300,
      310,
      320,
      330,
      340,
      350,
      360,
      370,
      380,
      390,
      400,
      410,
      420,
      430,
      440,
      450,
      460,
      470,
      480,
      490,
      500,
      510,
      520,
      530,
      540,
      550,
      560,
      570,
      580,
      590,
      600,
      610,
      620,
      630,
      640,
      650,
      660,
      670,
      680,
      690,
      700,
      710,
      720,
      730,
      740,
      750,
      760,
      770,
      780,
      790,
      800,
      810,
      820,
      830,
      840,
      850,
      860,
      870,
      880,
      890,
      900,
      910,
      920,
      930,
      940,
      950,
      960,
      970,
      980,
      990,
      1000
    ],
    "loss": [
      10.9107,
      8.9792,
      8.3772,
      7.5992,
      6.8067,
      6.114,
      5.6044,
      5.1818,
      5.0737,
      5.1798,
      4.8934,
      4.8136,
      4.8646,
      4.632,
      4.3631,
      4.3017,
      4.6513,
      4.224,
      4.4035,
      4.5312,
      4.3757,
      4.3415,
      4.426,
      4.1584,
      4.2919,
      4.008,
      4.2495,
      3.9093,
      4.0037,
      4.2417,
      4.1215,
      4.2843,
      3.9099,
      3.6154,
      4.0448,
      3.6699,
      3.8075,
      3.6349,
      3.9178,
      3.7321,
      3.5536,
      3.8,
      3.4929,
      3.7542,
      3.5906,
      3.7722,
      3.753,
      3.6696,
      3.6493,
      3.6981,
      3.815,
      3.3554,
      3.4625,
      3.4195,
      3.5016,
      3.3554,
      3.5024,
      3.4529,
      3.4479,
      3.4616,
      3.098,
      3.7053,
      3.197,
      3.3235,
      3.3351,
      3.5246,
      3.4766,
      3.3277,
      3.3548,
      3.127,
      3.1375,
      3.445,
      3.1955,
      3.354,
      3.1424,
      3.1207,
      2.9724,
      2.9621,
      3.0943,
      3.1745,
      3.1618,
      3.1251,
      3.0224,
      3.0385,
      2.9206,
      3.193,
      3.0244,
      2.9316,
      3.0714,
      2.8252,
      2.7297,
      2.9859,
      2.7112,
      2.8199,
      3.2121,
      2.9181,
      2.7917,
      2.7748,
      2.8914,
      2.8983,
      2.9599
    ],
    "time": [
      896.25,
      144.57,
      142.49,
      145.87,
      144.3,
      1478.64,
      142.32,
      143.13,
      143.45,
      142.72,
      1905.01,
      145.35,
      144.05,
      141.76,
      143.62,
      1873.53,
      146.63,
      144.42,
      144.95,
      143.18,
      1878.44,
      144.92,
      146.22,
      145.15,
      144.57,
      1867.94,
      144.22,
      142.31,
      144.65,
      144.04,
      1885.35,
      144.73,
      143.89,
      143.47,
      143.39,
      1874.68,
      142.69,
      144.55,
      145.78,
      143.78,
      1883.92,
      142.85,
      144.38,
      143.0,
      142.68,
      1946.4,
      143.51,
      142.04,
      143.57,
      144.87,
      1876.95,
      145.27,
      144.11,
      144.69,
      144.67,
      1899.45,
      143.12,
      143.92,
      144.05,
      143.58,
      1935.15,
      141.91,
      142.83,
      143.98,
      145.0,
      1933.05,
      143.38,
      143.97,
      144.54,
      143.89,
      1946.83,
      144.27,
      143.77,
      144.46,
      147.71,
      1883.94,
      144.04,
      145.46,
      146.02,
      143.33,
      1870.11,
      143.28,
      143.49,
      144.47,
      143.27,
      1909.63,
      143.96,
      144.11,
      143.1,
      143.49,
      1911.37,
      145.14,
      141.92,
      141.83,
      144.23,
      1938.01,
      143.49,
      142.43,
      146.03,
      146.37,
      1864.0
    ],
    "mfu": [
      0,
      13.98,
      14.0,
      13.99,
      13.99,
      12.73,
      12.87,
      13.0,
      13.11,
      13.21,
      12.0,
      12.19,
      12.37,
      12.56,
      12.71,
      11.55,
      11.77,
      12.0,
      12.19,
      12.38,
      11.25,
      11.52,
      11.75,
      11.97,
      12.17,
      11.06,
      11.36,
      11.64,
      11.88,
      12.09,
      10.99,
      11.29,
      11.56,
      11.82,
      12.04,
      10.95,
      11.27,
      11.54,
      11.77,
      12.0,
      10.91,
      11.23,
      11.51,
      11.77,
      12.01,
      10.91,
      11.23,
      11.53,
      11.79,
      12.0,
      10.91,
      11.21,
      11.49,
      11.74,
      11.96,
      10.87,
      11.2,
      11.48,
      11.74,
      11.97,
      10.88,
      11.22,
      11.51,
      11.76,
      11.98,
      10.89,
      11.21,
      11.49,
      11.74,
      11.97,
      10.88,
      11.19,
      11.48,
      11.73,
      11.92,
      10.84,
      11.16,
      11.43,
      11.67,
      11.92,
      10.83,
      11.16,
      11.45,
      11.71,
      11.95,
      10.86,
      11.18,
      11.46,
      11.73,
      11.96,
      10.87,
      11.18,
      11.48,
      11.76,
      11.99,
      10.89,
      11.21,
      11.51,
      11.74,
      11.95,
      10.86
    ]
  },
  "model_info": {
    "parameters": "123.59M",
    "n_layer": "12",
    "n_head": "12",
    "n_embd": "768",
    "block_size": "256",
    "batch_size": "8",
    "learning_rate": 0.0003,
    "dropout": 0.1,
    "max_iters": "1000",
    "dataset": "shakespeare"
  }
}