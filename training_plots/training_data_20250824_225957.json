{
  "validation": {
    "steps": [
      0,
      50,
      100,
      150,
      200,
      250,
      300,
      350,
      400,
      450,
      500,
      550,
      600,
      650,
      700,
      750,
      800,
      850,
      900,
      950,
      1000
    ],
    "train_loss": [
      10.9076,
      6.0378,
      4.9064,
      4.5241,
      4.1744,
      4.0017,
      3.8476,
      3.6892,
      3.5721,
      3.4051,
      3.3612,
      3.161,
      3.0432,
      2.9061,
      2.7413,
      2.7398,
      2.5701,
      2.5173,
      2.4323,
      2.4484,
      2.314
    ],
    "val_loss": [
      10.8725,
      6.1451,
      5.2886,
      5.0414,
      4.959,
      4.899,
      4.7618,
      4.7474,
      4.7021,
      4.6081,
      4.6422,
      4.672,
      4.7298,
      4.8534,
      4.8276,
      4.7525,
      4.9019,
      4.8554,
      4.7777,
      4.8975,
      4.8976
    ]
  },
  "training": {
    "iters": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200,
      210,
      220,
      230,
      240,
      250,
      260,
      270,
      280,
      290,
      300,
      310,
      320,
      330,
      340,
      350,
      360,
      370,
      380,
      390,
      400,
      410,
      420,
      430,
      440,
      450,
      460,
      470,
      480,
      490,
      500,
      510,
      520,
      530,
      540,
      550,
      560,
      570,
      580,
      590,
      600,
      610,
      620,
      630,
      640,
      650,
      660,
      670,
      680,
      690,
      700,
      710,
      720,
      730,
      740,
      750,
      760,
      770,
      780,
      790,
      800,
      810,
      820,
      830,
      840,
      850,
      860,
      870,
      880,
      890,
      900,
      910,
      920,
      930,
      940,
      950,
      960,
      970,
      980,
      990,
      1000
    ],
    "loss": [
      10.938,
      8.9819,
      8.3649,
      7.5907,
      6.7999,
      6.1043,
      5.5863,
      5.1743,
      5.0556,
      5.1623,
      4.895,
      4.7998,
      4.858,
      4.6104,
      4.3405,
      4.2854,
      4.6265,
      4.1861,
      4.3672,
      4.5057,
      4.3374,
      4.3184,
      4.3907,
      4.1112,
      4.2458,
      3.9364,
      4.2047,
      3.8499,
      3.9294,
      4.1897,
      4.0231,
      4.2146,
      3.805,
      3.4869,
      3.9269,
      3.5346,
      3.6909,
      3.489,
      3.7848,
      3.6068,
      3.4285,
      3.6933,
      3.3296,
      3.5814,
      3.4397,
      3.6102,
      3.5812,
      3.4852,
      3.4848,
      3.5366,
      3.6479,
      3.18,
      3.2578,
      3.2193,
      3.2882,
      3.1518,
      3.3088,
      3.1987,
      3.2008,
      3.2287,
      2.8676,
      3.4777,
      2.9526,
      3.1027,
      3.0915,
      3.2389,
      3.2217,
      3.0723,
      3.0806,
      2.8919,
      2.8833,
      3.1774,
      2.9267,
      3.0635,
      2.8226,
      2.7878,
      2.6425,
      2.6428,
      2.7499,
      2.8332,
      2.8078,
      2.8378,
      2.7236,
      2.676,
      2.6261,
      2.8092,
      2.6931,
      2.5995,
      2.7332,
      2.4394,
      2.3976,
      2.6419,
      2.3249,
      2.4286,
      2.8919,
      2.5666,
      2.4448,
      2.3889,
      2.5623,
      2.51,
      2.5711
    ],
    "time": [
      807.39,
      119.41,
      120.65,
      120.77,
      119.71,
      1426.55,
      119.53,
      119.1,
      119.45,
      121.75,
      1822.87,
      119.65,
      118.62,
      121.43,
      120.1,
      1811.91,
      119.84,
      121.37,
      119.4,
      119.14,
      1800.78,
      120.99,
      120.18,
      119.76,
      119.07,
      1661.4,
      118.59,
      119.9,
      117.33,
      118.42,
      1875.46,
      118.52,
      119.31,
      118.41,
      119.87,
      1874.85,
      118.17,
      124.92,
      122.84,
      123.24,
      1807.18,
      120.41,
      118.07,
      119.81,
      118.57,
      1765.94,
      119.1,
      120.32,
      119.63,
      118.18,
      1890.92,
      119.43,
      118.32,
      118.95,
      123.08,
      1797.73,
      120.19,
      117.92,
      118.65,
      118.57,
      1820.56,
      131.67,
      119.32,
      126.96,
      122.3,
      1812.77,
      118.39,
      119.21,
      125.55,
      117.97,
      1701.99,
      100.34,
      100.36,
      100.55,
      100.41,
      1713.69,
      100.34,
      100.31,
      100.91,
      100.32,
      1687.58,
      102.19,
      103.11,
      103.89,
      104.12,
      1761.36,
      100.29,
      100.31,
      100.4,
      100.19,
      1757.71,
      101.07,
      100.12,
      101.26,
      100.64,
      1714.18,
      103.11,
      104.14,
      103.5,
      103.12,
      1630.36
    ],
    "mfu": [
      0,
      16.93,
      16.91,
      16.89,
      16.89,
      15.34,
      15.5,
      15.65,
      15.78,
      15.86,
      14.38,
      14.63,
      14.87,
      15.05,
      15.23,
      13.82,
      14.12,
      14.38,
      14.63,
      14.86,
      13.49,
      13.81,
      14.11,
      14.39,
      14.65,
      13.3,
      13.68,
      14.0,
      14.32,
      14.59,
      13.24,
      13.62,
      13.96,
      14.27,
      14.53,
      13.18,
      13.57,
      13.84,
      14.1,
      14.33,
      13.01,
      13.38,
      13.76,
      14.07,
      14.37,
      13.04,
      13.44,
      13.77,
      14.09,
      14.39,
      13.06,
      13.44,
      13.81,
      14.13,
      14.36,
      13.03,
      13.41,
      13.78,
      14.11,
      14.4,
      13.07,
      13.3,
      13.67,
      13.89,
      14.15,
      12.85,
      13.27,
      13.64,
      13.89,
      14.21,
      12.91,
      13.63,
      14.28,
      14.87,
      15.39,
      13.97,
      14.59,
      15.14,
      15.63,
      16.08,
      14.6,
      15.11,
      15.56,
      15.95,
      16.3,
      14.78,
      15.32,
      15.8,
      16.24,
      16.63,
      15.08,
      15.57,
      16.04,
      16.43,
      16.79,
      15.23,
      15.67,
      16.04,
      16.39,
      16.71,
      15.17
    ]
  },
  "model_info": {
    "parameters": "123.59M",
    "n_layer": "12",
    "n_head": "12",
    "n_embd": "768",
    "block_size": "256",
    "batch_size": "8",
    "learning_rate": 0.0003,
    "dropout": 0.1,
    "max_iters": "1000",
    "dataset": "shakespeare"
  }
}