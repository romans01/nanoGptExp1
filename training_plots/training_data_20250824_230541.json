{
  "validation": {
    "steps": [
      0,
      50,
      100,
      150,
      200,
      250,
      300,
      350,
      400,
      450,
      500,
      550,
      600,
      650,
      700,
      750,
      800,
      850,
      900,
      950,
      1000
    ],
    "train_loss": [
      10.9079,
      6.0399,
      4.914,
      4.539,
      4.2177,
      4.0861,
      3.9625,
      3.8293,
      3.7244,
      3.5917,
      3.5739,
      3.4117,
      3.341,
      3.2399,
      3.1327,
      3.1531,
      3.0222,
      3.0045,
      2.958,
      2.9788,
      2.8642
    ],
    "val_loss": [
      10.8724,
      6.1481,
      5.3017,
      5.0521,
      4.9892,
      4.9564,
      4.8565,
      4.8747,
      4.8189,
      4.7519,
      4.8154,
      4.8396,
      4.887,
      5.0149,
      4.9704,
      4.8867,
      5.0115,
      4.9707,
      4.8647,
      4.973,
      4.958
    ]
  },
  "training": {
    "iters": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200,
      210,
      220,
      230,
      240,
      250,
      260,
      270,
      280,
      290,
      300,
      310,
      320,
      330,
      340,
      350,
      360,
      370,
      380,
      390,
      400,
      410,
      420,
      430,
      440,
      450,
      460,
      470,
      480,
      490,
      500,
      510,
      520,
      530,
      540,
      550,
      560,
      570,
      580,
      590,
      600,
      610,
      620,
      630,
      640,
      650,
      660,
      670,
      680,
      690,
      700,
      710,
      720,
      730,
      740,
      750,
      760,
      770,
      780,
      790,
      800,
      810,
      820,
      830,
      840,
      850,
      860,
      870,
      880,
      890,
      900,
      910,
      920,
      930,
      940,
      950,
      960,
      970,
      980,
      990,
      1000
    ],
    "loss": [
      10.9377,
      8.982,
      8.3649,
      7.5916,
      6.8016,
      6.1098,
      5.5867,
      5.177,
      5.0788,
      5.1772,
      4.9011,
      4.8078,
      4.8602,
      4.618,
      4.3651,
      4.3148,
      4.6497,
      4.2103,
      4.3993,
      4.5401,
      4.3736,
      4.3425,
      4.4304,
      4.1863,
      4.3118,
      4.0146,
      4.3094,
      3.9358,
      4.0212,
      4.2655,
      4.1408,
      4.3237,
      3.957,
      3.6312,
      4.0575,
      3.7356,
      3.9064,
      3.6537,
      3.9802,
      3.7687,
      3.5979,
      3.8272,
      3.525,
      3.7852,
      3.6311,
      3.8497,
      3.8472,
      3.6786,
      3.7527,
      3.7359,
      3.8473,
      3.3929,
      3.5191,
      3.4828,
      3.5503,
      3.4175,
      3.5464,
      3.4649,
      3.5024,
      3.5179,
      3.1641,
      3.7739,
      3.2612,
      3.3875,
      3.4401,
      3.6001,
      3.5332,
      3.4459,
      3.4552,
      3.2226,
      3.2638,
      3.5333,
      3.2828,
      3.4411,
      3.2519,
      3.1954,
      3.0765,
      3.1209,
      3.2193,
      3.3074,
      3.3016,
      3.27,
      3.1627,
      3.1596,
      3.0386,
      3.2987,
      3.1296,
      3.0301,
      3.1979,
      2.9887,
      2.8632,
      3.0895,
      2.8755,
      2.9478,
      3.3686,
      3.0849,
      2.9167,
      2.9216,
      3.0291,
      3.075,
      3.1115
    ],
    "time": [
      932.39,
      141.79,
      141.48,
      141.25,
      139.35,
      1498.92,
      142.57,
      140.44,
      145.73,
      155.12,
      1915.59,
      140.62,
      144.29,
      139.2,
      145.88,
      1912.14,
      150.29,
      141.21,
      141.77,
      141.47,
      1950.65,
      142.25,
      147.17,
      157.43,
      146.24,
      1924.59,
      156.9,
      143.61,
      141.43,
      145.38,
      1915.57,
      145.84,
      146.65,
      145.83,
      140.32,
      1915.92,
      151.55,
      142.83,
      142.68,
      144.07,
      1906.92,
      143.72,
      154.22,
      145.57,
      143.62,
      1895.41,
      144.43,
      140.87,
      142.9,
      141.49,
      1900.68,
      156.38,
      155.64,
      150.38,
      155.89,
      1870.32,
      142.31,
      143.13,
      141.98,
      149.94,
      1919.84,
      152.97,
      143.91,
      144.74,
      139.85,
      1854.68,
      141.48,
      141.18,
      141.87,
      142.95,
      1871.58,
      142.49,
      165.58,
      144.04,
      144.1,
      1884.13,
      143.8,
      140.52,
      141.55,
      141.52,
      1852.63,
      143.24,
      142.85,
      140.87,
      140.22,
      1859.82,
      141.72,
      141.98,
      142.95,
      147.38,
      1940.94,
      147.02,
      141.99,
      142.82,
      159.78,
      1896.46,
      147.76,
      166.12,
      146.34,
      141.82,
      1937.69
    ],
    "mfu": [
      0,
      14.26,
      14.26,
      14.26,
      14.29,
      12.99,
      13.11,
      13.24,
      13.3,
      13.28,
      12.05,
      12.29,
      12.46,
      12.66,
      12.78,
      11.61,
      11.79,
      12.05,
      12.27,
      12.47,
      11.33,
      11.61,
      11.83,
      11.93,
      12.12,
      11.01,
      11.2,
      11.49,
      11.77,
      11.98,
      10.89,
      11.18,
      11.44,
      11.69,
      11.96,
      10.87,
      11.11,
      11.42,
      11.69,
      11.93,
      10.84,
      11.16,
      11.36,
      11.61,
      11.86,
      10.78,
      11.1,
      11.42,
      11.7,
      11.96,
      10.87,
      11.07,
      11.26,
      11.48,
      11.63,
      10.57,
      10.94,
      11.26,
      11.55,
      11.75,
      10.68,
      10.93,
      11.24,
      11.51,
      11.81,
      10.74,
      11.09,
      11.41,
      11.7,
      11.94,
      10.86,
      11.19,
      11.29,
      11.56,
      11.81,
      10.74,
      11.07,
      11.4,
      11.69,
      11.95,
      10.86,
      11.19,
      11.48,
      11.77,
      12.03,
      10.94,
      11.27,
      11.57,
      11.83,
      12.01,
      10.92,
      11.2,
      11.5,
      11.77,
      11.86,
      10.78,
      11.07,
      11.18,
      11.44,
      11.72,
      10.65
    ]
  },
  "model_info": {
    "parameters": "123.59M",
    "n_layer": "12",
    "n_head": "12",
    "n_embd": "768",
    "block_size": "256",
    "batch_size": "8",
    "learning_rate": 0.0003,
    "dropout": 0.1,
    "max_iters": "1000",
    "dataset": "shakespeare"
  }
}