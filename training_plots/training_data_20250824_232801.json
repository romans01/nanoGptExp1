{
  "validation": {
    "steps": [
      0,
      50,
      100,
      150,
      200,
      250,
      300,
      350,
      400,
      450,
      500,
      550,
      600,
      650,
      700,
      750,
      800,
      850,
      900,
      950,
      1000
    ],
    "train_loss": [
      10.8512,
      6.2836,
      5.4528,
      4.8503,
      4.4569,
      4.3244,
      4.1509,
      4.007,
      3.8886,
      3.7806,
      3.7696,
      3.6166,
      3.5912,
      3.4859,
      3.3965,
      3.4361,
      3.3187,
      3.2998,
      3.2701,
      3.2977,
      3.1833
    ],
    "val_loss": [
      10.8349,
      6.316,
      5.6988,
      5.212,
      5.0775,
      5.0407,
      4.8689,
      4.8146,
      4.732,
      4.6768,
      4.7017,
      4.7274,
      4.7665,
      4.8608,
      4.7952,
      4.7337,
      4.8589,
      4.8003,
      4.6825,
      4.8058,
      4.7703
    ]
  },
  "training": {
    "iters": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      110,
      120,
      130,
      140,
      150,
      160,
      170,
      180,
      190,
      200,
      210,
      220,
      230,
      240,
      250,
      260,
      270,
      280,
      290,
      300,
      310,
      320,
      330,
      340,
      350,
      360,
      370,
      380,
      390,
      400,
      410,
      420,
      430,
      440,
      450,
      460,
      470,
      480,
      490,
      500,
      510,
      520,
      530,
      540,
      550,
      560,
      570,
      580,
      590,
      600,
      610,
      620,
      630,
      640,
      650,
      660,
      670,
      680,
      690,
      700,
      710,
      720,
      730,
      740,
      750,
      760,
      770,
      780,
      790,
      800,
      810,
      820,
      830,
      840,
      850,
      860,
      870,
      880,
      890,
      900,
      910,
      920,
      930,
      940,
      950,
      960,
      970,
      980,
      990,
      1000
    ],
    "loss": [
      10.8915,
      9.138,
      8.6639,
      7.7655,
      6.9623,
      6.3456,
      5.9625,
      5.7087,
      5.5564,
      5.6883,
      5.4455,
      5.2651,
      5.2193,
      4.9915,
      4.7353,
      4.5946,
      4.9705,
      4.4815,
      4.6636,
      4.7987,
      4.6167,
      4.5366,
      4.613,
      4.3845,
      4.5555,
      4.2408,
      4.5308,
      4.1988,
      4.2574,
      4.5486,
      4.2932,
      4.607,
      4.144,
      3.7946,
      4.2372,
      3.8838,
      4.0973,
      3.7758,
      4.218,
      3.949,
      3.7323,
      4.0602,
      3.6887,
      3.9891,
      3.8001,
      4.0216,
      3.9578,
      3.8998,
      3.9643,
      3.8632,
      4.045,
      3.5587,
      3.7007,
      3.6784,
      3.7934,
      3.5902,
      3.782,
      3.7103,
      3.7293,
      3.7306,
      3.3526,
      4.0906,
      3.4786,
      3.6728,
      3.6869,
      3.8445,
      3.7639,
      3.6249,
      3.7198,
      3.5192,
      3.5078,
      3.7749,
      3.5094,
      3.673,
      3.5075,
      3.4179,
      3.3263,
      3.3898,
      3.4429,
      3.5956,
      3.5775,
      3.5009,
      3.4493,
      3.3947,
      3.3072,
      3.6005,
      3.4176,
      3.3529,
      3.442,
      3.1883,
      3.1299,
      3.3976,
      3.1312,
      3.2295,
      3.6153,
      3.4049,
      3.2231,
      3.2047,
      3.4031,
      3.392,
      3.4081
    ],
    "time": [
      1378.45,
      324.67,
      326.15,
      341.77,
      177.17,
      1934.95,
      318.95,
      310.17,
      330.9,
      171.56,
      1980.98,
      476.62,
      453.78,
      449.26,
      157.25,
      2673.23,
      183.27,
      162.06,
      183.96,
      321.09,
      2351.92,
      330.49,
      363.0,
      468.34,
      333.23,
      2148.73,
      326.03,
      325.87,
      155.66,
      155.14,
      2267.99,
      308.57,
      325.04,
      301.19,
      335.5,
      2284.63,
      156.77,
      324.45,
      320.37,
      302.72,
      2278.49,
      312.8,
      158.35,
      169.88,
      170.86,
      2560.68,
      380.75,
      563.16,
      376.96,
      373.66,
      2491.19,
      169.23,
      172.1,
      179.29,
      374.98,
      2435.32,
      357.0,
      167.82,
      347.29,
      333.45,
      2159.22,
      148.99,
      150.8,
      249.73,
      337.19,
      2273.1,
      318.64,
      316.68,
      157.34,
      318.39,
      2243.44,
      317.05,
      314.74,
      151.14,
      160.79,
      2054.02,
      305.89,
      311.21,
      308.79,
      310.55,
      2142.94,
      301.04,
      302.38,
      302.14,
      306.26,
      2255.35,
      150.61,
      152.16,
      148.02,
      429.52,
      2215.43,
      296.21,
      289.47,
      278.3,
      253.67,
      2524.47,
      272.42,
      266.53,
      268.93,
      301.8,
      2269.78
    ],
    "mfu": [
      0,
      6.23,
      6.22,
      6.19,
      6.71,
      6.15,
      6.17,
      6.2,
      6.19,
      6.75,
      6.18,
      5.98,
      5.83,
      5.7,
      6.41,
      5.85,
      6.37,
      6.98,
      7.38,
      7.27,
      6.63,
      6.58,
      6.48,
      6.26,
      6.24,
      5.71,
      5.76,
      5.8,
      6.52,
      7.17,
      6.54,
      6.55,
      6.51,
      6.53,
      6.48,
      5.92,
      6.62,
      6.58,
      6.55,
      6.57,
      6.0,
      6.04,
      6.72,
      7.23,
      7.69,
      7.0,
      6.83,
      6.51,
      6.39,
      6.3,
      5.75,
      6.37,
      6.91,
      7.34,
      7.15,
      6.52,
      6.43,
      6.99,
      6.87,
      6.79,
      6.21,
      6.94,
      7.59,
      7.64,
      7.48,
      6.82,
      6.77,
      6.73,
      7.34,
      7.24,
      6.61,
      6.59,
      6.57,
      7.25,
      7.78,
      7.1,
      7.05,
      7.0,
      6.95,
      6.91,
      6.31,
      6.35,
      6.38,
      6.42,
      6.43,
      5.88,
      6.63,
      7.3,
      7.93,
      7.61,
      6.94,
      6.93,
      6.94,
      6.97,
      7.07,
      6.44,
      6.54,
      6.64,
      6.73,
      6.73,
      6.14
    ]
  },
  "model_info": {
    "parameters": "123.59M",
    "n_layer": "12",
    "n_head": "12",
    "n_embd": "768",
    "block_size": "256",
    "batch_size": "8",
    "learning_rate": 0.0003,
    "dropout": 0.1,
    "max_iters": "1000",
    "dataset": "shakespeare"
  }
}